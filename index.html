<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Browser SLM Chat - WebLLM</title>
    
    <!-- PWA Meta Tags -->
    <meta name="description" content="Run AI models directly in your browser using WebGPU - 100% private, no server required">
    <meta name="theme-color" content="#6366f1">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="apple-mobile-web-app-title" content="SLM Chat">
    
    <!-- PWA Manifest & Icons -->
    <link rel="manifest" href="/manifest.json">
    <link rel="icon" type="image/svg+xml" href="/icons/favicon.svg">
    <link rel="apple-touch-icon" href="/icons/icon-192.png">
    
    <link rel="stylesheet" href="/src/styles.css" />
  </head>
  <body>
    <div class="container">
      <header>
        <h1>ðŸ§  Browser SLM Chat</h1>
        <p class="subtitle">
          Powered by WebLLM â€¢ Runs 100% in your browser â€¢ 
          <a href="https://github.com/micrometre/web-llm/tree/master" target="_blank" rel="noopener">Source Code</a>
          <button id="install-btn" class="install-btn hidden">ðŸ“² Install App</button>
        </p>
      </header>

      <div class="model-controls">
        <div class="model-selector">
          <label for="model-select">Select Model:</label>
          <select id="model-select">
            <!-- Tiny Models (< 500M) - Best for low-end devices -->
            <option value="SmolLM2-360M-Instruct-q4f32_1-MLC">SmolLM2 360M (Tiny, ~200MB)</option>
            <option value="Qwen2.5-0.5B-Instruct-q4f32_1-MLC">Qwen2.5 0.5B (Fastest) âœ“</option>
            
            <!-- Small Models (1B) - Good balance for mobile -->
            <option value="gemma-3-1b-it-q4f32_1-MLC">Gemma 3 1B (Mobile Optimized) ðŸš€</option>
            <option value="Llama-3.2-1B-Instruct-q4f32_1-MLC" selected>Llama 3.2 1B (Recommended)</option>
            <option value="TinyLlama-1.1B-Chat-v1.0-q4f32_1-MLC">TinyLlama 1.1B</option>
            
            <!-- Medium Models (1.5B-2B) -->
            <option value="Qwen2.5-1.5B-Instruct-q4f32_1-MLC">Qwen2.5 1.5B</option>
            <option value="gemma-2-2b-it-q4f32_1-MLC">Gemma 2 2B</option>
            
            <!-- Larger Models (3B+) - Requires 4GB+ RAM -->
            <option value="Phi-3.5-mini-instruct-q4f32_1-MLC">Phi-3.5 Mini 3.8B (Microsoft)</option>
            <option value="Llama-3.2-3B-Instruct-q4f32_1-MLC">Llama 3.2 3B</option>
            <option value="Mistral-7B-Instruct-v0.3-q4f32_1-MLC">Mistral 7B (8GB+ RAM)</option>
          </select>
        </div>
        <button id="load-btn" class="btn btn-primary">Load Model</button>
        <button id="unload-btn" class="btn btn-secondary" disabled>Unload</button>
      </div>

      <div id="progress-container" class="progress-container hidden">
        <div class="progress-info">
          <span id="progress-text">Initializing...</span>
          <span id="progress-percent">0%</span>
        </div>
        <div class="progress-bar">
          <div id="progress-fill" class="progress-fill"></div>
        </div>
      </div>

      <div id="gpu-info" class="gpu-info"></div>

      <div class="chat-container">
        <div id="chat-messages" class="chat-messages">
          <div class="welcome-message">
            <p>ðŸ‘‹ Welcome! Select a model and click <strong>Load Model</strong> to start chatting.</p>
            <p class="note">Models are cached in OPFS after first download for faster loading next time.</p>
          </div>
        </div>

        <form id="chat-form" class="chat-input-container">
          <textarea
            id="user-input"
            placeholder="Type your message..."
            rows="1"
            disabled
          ></textarea>
          <button type="submit" id="send-btn" class="btn btn-primary" disabled>
            Send
          </button>
        </form>
      </div>

      <div class="stats-bar">
        <span id="stats-text">No model loaded</span>
      </div>
    </div>

    <script type="module" src="/src/main.js"></script>
    
    <!-- Register Service Worker & PWA Install -->
    <script>
      // Service Worker Registration
      if ('serviceWorker' in navigator) {
        window.addEventListener('load', () => {
          navigator.serviceWorker.register('/sw.js')
            .then((reg) => console.log('[PWA] Service Worker registered'))
            .catch((err) => console.log('[PWA] Service Worker registration failed:', err));
        });
      }

      // PWA Install Prompt
      let deferredPrompt;
      const installBtn = document.getElementById('install-btn');

      window.addEventListener('beforeinstallprompt', (e) => {
        e.preventDefault();
        deferredPrompt = e;
        installBtn.classList.remove('hidden');
      });

      installBtn.addEventListener('click', async () => {
        if (!deferredPrompt) return;
        deferredPrompt.prompt();
        const { outcome } = await deferredPrompt.userChoice;
        console.log('[PWA] Install outcome:', outcome);
        deferredPrompt = null;
        installBtn.classList.add('hidden');
      });

      window.addEventListener('appinstalled', () => {
        console.log('[PWA] App installed');
        installBtn.classList.add('hidden');
      });
    </script>
  </body>
</html>
